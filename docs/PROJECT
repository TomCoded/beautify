(C) 2002 Tom White All Rights Reserved

----------------------

See README file for program instructions.

----------------------

The minimum requirements initially propsed for the project were as
follows:

 - To produce a two-pass photon-mapping renderer
 - To allow for the rendering of the following objects
   -Spheres
   -tapered Cylinders
   -Planes
 - To generate all images as a function of some time t, allowing for
	consistent frame generation.
 - To allow for reflective, refractive, and translucent objects.

Extensions proposed for the project included:
 - Rendering of polygonal meshes
 - Texture-mapping
 - Rendering of water as an implicit surface
 - Rendering of water as a particle-defined implicit surface
 - Batch processing and video file generation
 - Multi-threaded implementation

The status of the project goals:
 - To produce a two-pass photon-mapping renderer:
	In the first pass, the Application produces a general global
photon map for photons stored at diffuse surfaces.  This can be saved
to or read from a file.  During the second pass, the application
produces sample rays aimed from a camera into the scene.  When these
sample rays hit an object, the Renderer sums the specular contribution
to the object's color (generated by standard ray tracing) and the
diffuse contribution, as extrapolated from the flux through the
surface as represented by the global photon map.
   
 - To allow for the rendering of the following objects
   -Spheres
   -tapered Cylinders
   -Planes
	Spheres and Planes seem to be functioning adequately.  The
generic plane has been limited in range to produce a non-infinite
shape.  Tapered Cyclinders are implemented, but have not been tested
extensively. 

 - To generate all images as a function of some time t, allowing for
	consistent frame generation.
	 All images are generated as a function of time t.  This
information is stored in the Surface class and can be updated to
change the state of the scene, if the surface's transforms are not
static over time.
	Frame consistency over time required seeding the random number
system rand48() used to produce photon emissions from light sources
consistantly.  In an earlier version, the renderer class would do this,
setting the seed before each light emitted its photons. A default
seed value of 21 was picked, because it looked pretty.  Different seed
values for the photon mapper produced *radically* different images,
with patches, lines, spots, and or patterns. A more recent version
fixes this problem. Because the scene composition
varies over time (i.e. between frames), different physical interactions
occur and the RNG was called a variable number of times between photons,
resulting in different light patterns. Because we are not truly emitting
the number of photons that exist IRL, we want a consistent pattern. This
is achieved by storing a seed for the next photon after each photon is
generated at the light but before it is traced into the (time-varying)
image.

 - To allow for reflective, refractive, and translucent objects.
    	No tests have been done to demonstrate reflection, although it
is implemented in diffuse lighting.  When a photon is thrown from a
light, if it reflects from a diffuse surface a copy of it is stored
there and a copy is made, with its intensity in each color channel
adjusted for the possibility of surviving the reflection, and the copy
is reflected of the object.  
	Refractive objects have not been implemented.
	Translucent objects have not been implemented as such;
however, the extension to participating media suggests that it is
possible to generate translucent objects given the right scattering
coefficient of the medium.

Extensions:
	
The project renders to the openGL window instead of a basic XWindow;
this allows for animation on window repaint if the change in time per
frame is not zero, and for a window repaint on window state changes.

	The FunTransform4Dd class was written to handle user-defined
transforms that vary as a function of time. The user must enter values
for the local to world, world to local, and local to world normal
transformations.  Acceptable values are arbitrary combinations of
polynomials/trig functions for each place in a given matrix.  
   	 When the user does not want to use transforms as a function
of time, he may use the scale(), rotate() and transform() keywords to
generate Transform4Dd's.  This saves computation in Scenes limited to
these transformations or with both transformations.

The following Extensions have been added to the project:
Batch processing of images to produce an arbitrary number of frames in
a sequence has been implemented.  This produces output in .jpg format
that can then be converted to mpeg-1 or other video formats.

Surfaces and Shapes have support for objects defined implicitly.
Spheres have had a function added to them to return the value of the
implicit function of the sphere at a given point in 3-space.

The photon mapper has been extended to participating media.  The
participating media works identically to regular materials except:
 - Photons generated are stored in a seperate, volume photon map.
 - Luminance, rather than flux, is determined when gathering image
data.  This means that there is no adjustment made for the normal of
the *inside* of an object, because it doesn't have one.  Also, this
means that the photons used to determine radiance are divided by the
volume of a sphere rather than the area of a disc, because they are
likely to be distributed with more variation in three dimensions about
the medium than are points on a surface.

 - Russian Roulette is adjusted; the sample ray is fired to just
inside the medium; at that point, it is randomly chosen to continue,
get absorbed, or get scattered.  This decision is made according to
the scattering coefficient of the medium.

The photon map is programmed to support three storage modes:
 - Unsorted; this mode is not available to the user, but was used
	originally and remains in the code base.
 - Quicksorted; this mode is available to the user.  It quicksorts the
	photons in the map along dimension x.
 - kd-Tree; this is the default mode.  It sorts the photon map into a
  	3-dimensionsal kd-Tree by default after it is generated.  

----------------------

Classes:

Shape/
The basic shape classes.  They contain methods for intersections.

Shape/TaperedCyl
Shape/Plane
Shape/Sphere
Sphere also includes an implicit() function that returns the value of
the implicit function of a sphere at a given point in 3-space.

Shader/
Different types of shaders.  These were part of the original ray
tracer, but are basically legacy items at this point.

Shader/LambertShader

Surface/
Each surface has a shape, a shader, and the relevant transforms.  This
includes "FunTransforms" if the user has entered a custom
transformation.  Current Transform4Dd's are created any time a surface
is told that there has been a time change.

Scene/
gets input and sends it to the Renderer.  Also maintains the vectors
of objects (Lights, Cameras, Surfaces, Shapes, Materials...) for the
whole kitten-caboodle.

Renderer/
Traces photons or sample rays through a given scene, generating a
photon map, and later querying the map for luminanace information that
it uses to generate colors for sample rays shot from the eye.

Light/
Lights emit photons, and are referenced when computing specular
highlights.

Light/PointLight
Light/DirLight
Directional Lights are lights outside the Scene, with all emitted
perpendicular to a plane which is defined as one whose normal is the
direction vector.  A location on the plane is chosen randomly, and a
photon is emitted.

Light/PointLight/DiffusePointLight
A diffuse point light randomly emits a photon in any spherical
direction.

Light/SquareLight
A Square Light is a plane where light is emitted in a randomly
selected vector from the hemisphere in which the normal is directed.
The random selection is made according to a cosine distribution, with
the direction parallell to the normal being the most likely direction
for photonic emission.

Hit/
just some hitpoint data

Camera/
Your basic but annoying camera.

Material/
Contains the basic material properties of a Surface.  The material is
also responsible for a part of the simplified BRDF done by the photon
mapper.  (Lambertian.)  Specifically, it multiplies a given photon by
the diffuse reflection coefficients given.  Russian Roulette to
determine the future of the photon also occurs here.

Material/Participating
This is for Materials that are participating media.  See the section
on extensions.

PhotonMap/
This holds the PhotonMap.  It maintains an array of photons for quick
access time, and this array is used when the photons are quicksorted
or used in unsorted fashion.  There is also an array of pointers to
photons, the kdTree[] array, which represents the kdTree.  Each photon
pointer in this array represents a node of the kdTree; pointers are
used to prevent the need to actually swap around the photons during
the sorting, and generally save time.  

The PhotonMap stores it's format in UNFORMATTED, QUICKSORTED, or
KD_TREE storage mode.  UNFORMATTED mode simply leaves the photons
unsorted, and takes a ridiculously long time to search for nearest
neighbors.  Quicksorted divides this time by roughly MAXSEARCHDIST /
DIMX, where DIMX is the spread of points across dimension x.  The
kdTree is optimized for nearest neighbor searching.

PhotonPriorityQueue/PhotonPriorityQueue.cc
When doing nearest neighbor searching in the kd-Tree, a priority queue
is the most efficient means of eliminating unwanted farthest
neighbors.  This is a double linked list where the photon farthest
from the location in question is always on top, ready to be dropped.

Ray/
The simple Ray

TransformMaker/
Anonymous1's Transform Maker.

Defs.h
A few defines in the root directory

allIncludes.h
A master include file for most of the project.








